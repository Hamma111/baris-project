{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## necessary libraries needed\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options \n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from time import sleep\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "import cv2\n",
    "\n",
    "\n",
    "\n",
    "## to make browser look like a real browser\n",
    "options = Options()\n",
    "options.add_argument(\"--disable-blink-features\")\n",
    "options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "options.add_argument(\"start-maximized\")\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "options.add_experimental_option('useAutomationExtension', False)\n",
    "dr = webdriver.Chrome(options=options)\n",
    "\n",
    "\n",
    "\n",
    "## visiting the website and waiting for 10 seconds\n",
    "link = 'https://www.citychain.com.hk/en/forhim'\n",
    "dr.get(link)\n",
    "# sleep(10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## extracting attributes of products\n",
    "soup = BeautifulSoup(dr.page_source)\n",
    "\n",
    "items = soup.findAll('div', {\"class\": \"w_pro_pic22 pro_letter\"})\n",
    "img_urls = [item.find('img')['src'] for item in items]\n",
    "titles = [x.text for x in soup.findAll('div', {'class': 'w_pro_text22'})]\n",
    "prod_ids = [x.text for x in soup.findAll('div', {'class': 'w_pro_bh17'})]\n",
    "original_prices = []\n",
    "sale_prices = [] \n",
    "for x in soup.findAll('div', {'class': 'w_pro_price22'}):\n",
    "    try:\n",
    "        original_prices.append(x.find('del').text)\n",
    "    except:\n",
    "        try:\n",
    "            original_prices.append(x.find('dd').text.strip())\n",
    "        except:\n",
    "            original_prices.append('N\\A')\n",
    "    try:\n",
    "        sale_prices.append(x.find('dt').text)\n",
    "    except:\n",
    "        sale_prices.append('N\\A')\n",
    "prod_urls = [\"https://www.citychain.com.hk\" + x.find('a')['href'] for x in \n",
    "             soup.findAll('figure', {'class':\"col-xs-6 w_pro_list22_box\"})]\n",
    "        \n",
    "\n",
    "\n",
    "## creating a dataframe for csv file        \n",
    "dff = pd.DataFrame({\n",
    "    'ProductName': titles,\n",
    "    'ProductID': prod_ids,\n",
    "    'OriginalPrice': original_prices,\n",
    "    'SalePrice': sale_prices,\n",
    "#     'ProductURL': prod_urls,\n",
    "#     'ProductImageURL': img_urls\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## saving the csv files for a particular category\n",
    "categ_name = 'hhs.csv'\n",
    "dff.to_csv(categ_name, index=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
